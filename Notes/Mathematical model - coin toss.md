
# Motivation
In this project we investigate the possibility of interleaving the measurements and the estimation shot. 

###### Aim
We aim at training the RL agent to overcome heuristic-methods for optimised parameters. Once this is the case we can interpret the RL strategy and learn from it. 

###### Experiment
We use the simple [[Model-of-experiement]] that is parametrised by the:
- Number of shots $N$
- Correlation time of the environment $\tau_c$, 
- Fluctuation amplitude $\sigma$ 
- Average field $B_0$ 
We use the [[model-of-the-fluctuations]] that is given by O-U noise. We start with the initial condition. 

##### Method
We test the [[heuristic-methods]] against the [[Reinforcement-Learning-model]]. For the heuristic-method we perform the optimisation of their parameters, such that a viable comparison is made. 
